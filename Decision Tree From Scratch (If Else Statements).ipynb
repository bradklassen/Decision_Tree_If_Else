{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree From Scratch Using If/Else Statements\n",
    "This notebook will explore building a decision tree in the most basic way possible by using a series of if/else statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#1)\n",
    "2. [Measuring Node Impurity](#2)\n",
    "    1. [Gini Index](#3)\n",
    "    1. [Entropy](#4)\n",
    "3. [Classifying Predictions](#5)\n",
    "4. [Building the Tree](#6)\n",
    "    1. [Simulate Training Data](#7)\n",
    "5. [Predicting New Observations](#8)\n",
    "    1. [Simulate Testing Data](#9)\n",
    "6. [References](#10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "## Introduction\n",
    "Many tutorials explain how to build a decision tree from scratch but often complicate the process. There are more optimal ways to build the model, however this notebook was created to increase interpretability. To make the process easier, both the inputs and outputs are binary. We will therefore be creating a classification decision tree. The notebook assumes the reader has basic knowledge of decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "## Measuring Node Impurity\n",
    "In order to build the decision tree, there must be a way to evaluate which input is the best question to ask at the given time. At every node in the tree one must evaluate the quality of inputs at the current depth. One can evaluate the quality of the split using node impurity calculations. For classification, the two typical methods used to measure node impurity are Gini Index and Entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "### Gini Index\n",
    "Gini Index can be thought of as the degree or probability of a particular variable being wrongly classified when it is randomly chosen. [1](https://blog.quantinsti.com/gini-index/) Gini index varies between 0 and 1, where 0 indicates all elements belong to a certain class, and 1 indicates that the elements are randomly distributed between various classes. [1](https://blog.quantinsti.com/gini-index/) The function below takes four inputs, zero correct indicates the observations of class 0 that are correct, zero incorrect indicates the observations of class 0 that are incorrect. One correct indicates the observations of class 1 that are correct, one incorrect indicates the observations of class 1 that are incorrect. The gini index is calculated using the formula below, where c is the number of classes, and $p_{i}$ is the proportion of the samples that belong to class c for a particular node.\n",
    "\n",
    "$$\n",
    "\\operatorname{Gini}=1-\\sum_{i=1}^{C}\\left(p_{i}\\right)^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini = function(zero_correct, zero_incorrect, one_correct, one_incorrect){\n",
    "  \n",
    "  gini_one = 1 - ((one_correct / (one_correct + one_incorrect))^2 + (one_incorrect / (one_correct + one_incorrect))^2)\n",
    "  gini_zero = 1 - ((zero_correct / (zero_correct + zero_incorrect))^2 + (zero_incorrect / (zero_incorrect + zero_correct))^2)\n",
    "  \n",
    "  return((((one_correct + one_incorrect) / (one_correct + one_incorrect + zero_correct + zero_incorrect)) * gini_one) \n",
    "         + (((zero_correct + zero_incorrect) / (one_correct + one_incorrect + zero_correct + zero_incorrect)) * gini_zero))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "### Entropy\n",
    "Entropy can be roughly thought of as the amount of variance within the data, which is the degree of uncertainty, impurity or disorder within the node. [1](https://blog.quantinsti.com/gini-index/) The entropy function created below takes the same inputs as the gini function.  The entropy is calculated using the formula below, where c is the number of classes, and $p_{i}$ is the proportion of the samples that belong to class c for a particular node.\n",
    "\n",
    "$$\n",
    "\\text { Entropy }=\\sum_{i=1}^{C}-p_{i} \\times \\log _{2}\\left(p_{i}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = function(zero_correct, zero_incorrect, one_correct, one_incorrect){\n",
    "  \n",
    "  entropy_one = - ((one_correct / (one_correct + one_incorrect)) * log2(one_correct / (one_correct + one_incorrect)) \n",
    "                    + (one_incorrect / (one_correct + one_incorrect)) * log2(one_incorrect / (one_correct + one_incorrect)))\n",
    "  entropy_zero = - ((zero_correct / (zero_correct + zero_incorrect)) * log2(zero_correct / (zero_correct + zero_incorrect)) \n",
    "                     + (zero_incorrect / (zero_correct + zero_incorrect)) * log2(zero_incorrect / (zero_correct + zero_incorrect)))\n",
    "  \n",
    "  return(((one_correct + one_incorrect) / (one_correct + one_incorrect + zero_correct + zero_incorrect)) * entropy_one + \n",
    "           ((zero_correct + zero_incorrect) / (one_correct + one_incorrect + zero_correct + zero_incorrect)) * entropy_zero)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "### Classifying Predictions\n",
    "A third function has been created to evaluate the mode of the observations in each leaf. This will be used for prediction purposes. When given testing data, the prediction will be computed as the observation that occurs most often within the given leaf of the tree built from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = function(data){\n",
    "  unique_data = unique(data)\n",
    "  return(unique_data[which.max(tabulate(match(data, unique_data)))])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a> <br>\n",
    "## Building the Tree\n",
    "The following function will be used to create the classification decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = function(training_data){\n",
    "\n",
    "  # Number of observations\n",
    "  n = dim(training_data)[1]\n",
    "  \n",
    "  # Number of inputs\n",
    "  p = dim(training_data)[2] - 1\n",
    "  \n",
    "  # Create list of 0 & 1\n",
    "  values = c(0, 1)\n",
    "  \n",
    "  # Repeats list of 0 & 1 values, p times\n",
    "  values_p = lapply(numeric(p), function(x) values)\n",
    "  \n",
    "  # Finds each possible combination of 0 & 1 and stores it in a matrix\n",
    "  mat = as.matrix(expand.grid(values_p))\n",
    "\n",
    "  # Number of inputs at each depth of the tree\n",
    "  num_inputs = c(p:1)\n",
    "  \n",
    "  # Initialize count for adding values to list\n",
    "  count = 0\n",
    "  \n",
    "  # Create matrix for outputting results\n",
    "  tree_output = matrix(0, nrow = dim(mat)[1], ncol = p+1)\n",
    "  \n",
    "  # Iterate through each row of matrix to try all possible splits\n",
    "  for (b in c(1:dim(mat)[1])){\n",
    "    \n",
    "    # Restart data frame which will be broken down in the loop\n",
    "    training_data_loop = data.frame(training_data)\n",
    "    \n",
    "    # Each row in the matrix indicates a way of getting to leaf\n",
    "    for (i in c(1:dim(mat)[2])){\n",
    "      \n",
    "      # Create empty matrix to append gini values to\n",
    "      gini_values = matrix(0, nrow = as.numeric(num_inputs[i]))\n",
    "      \n",
    "      # Loop through number of inputs\n",
    "      for (j in c(1:num_inputs[i])){\n",
    "        \n",
    "        # Target variable = 0 (Assumes target variable is last column in data set)\n",
    "        if (length(training_data_loop[training_data_loop[[ncol(training_data_loop)]] == 0, j]) != 0){\n",
    "          zero_correct = mean(training_data_loop[training_data_loop[[ncol(training_data_loop)]] == 0, j])\n",
    "        } else {\n",
    "          zero_correct = 0\n",
    "        }\n",
    "        zero_incorrect = 1 - zero_correct\n",
    "        \n",
    "        # Target variable = 1 (Assumes target variable is last column in data set)\n",
    "        if (length(training_data_loop[training_data_loop[[ncol(training_data_loop)]] == 1, j]) != 0){\n",
    "          one_correct = mean(training_data_loop[training_data_loop[[ncol(training_data_loop)]] == 1, j]) \n",
    "        } else {\n",
    "          one_correct = 0\n",
    "        }\n",
    "        one_incorrect = 1 - one_correct\n",
    "        \n",
    "        # Append gini to gini_values matrix\n",
    "        gini_values[j] = gini(one_correct, one_incorrect, zero_correct, zero_incorrect)\n",
    "        \n",
    "        # Add 1 to count\n",
    "        count = count + 1\n",
    "        \n",
    "      }\n",
    "      \n",
    "      # Add obsevation from matrix to tree output\n",
    "      tree_output[b, j] = mat[b, i]\n",
    "      \n",
    "      # Removes input with best gini value because it will be used for the split\n",
    "      training_data_loop = training_data_loop[training_data_loop[which.min(gini_values)] == mat[b, i], - which.min(gini_values)]\n",
    "      \n",
    "    }\n",
    "    \n",
    "    # Classify the output as the mode of the observations in the leaf\n",
    "    tree_output[b, p+1] = mode(training_data_loop)\n",
    "    \n",
    "  }\n",
    "  \n",
    "  # Convert tree output to data frame\n",
    "  tree_output = as.data.frame(tree_output)\n",
    "  \n",
    "  # Make column names the same as the column names from the original data frame\n",
    "  colnames(tree_output) = head(names(training_data), n = p+1)\n",
    "                    \n",
    "  # Return the output of the tree\n",
    "  return(tree_output)\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> <br>\n",
    "### Simulate Training Data\n",
    "Training data will be simulated below to run through the tree function and create a tree with each possible combination of inputs and their predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   drinks exercises smokes relationship heart_pain\n",
      "1       0         0      0            0          1\n",
      "2       0         0      0            1          1\n",
      "3       0         0      1            0          0\n",
      "4       0         0      1            1          0\n",
      "5       0         1      0            0          1\n",
      "6       0         1      0            1          0\n",
      "7       0         1      1            0          1\n",
      "8       0         1      1            1          0\n",
      "9       1         0      0            0          0\n",
      "10      1         0      0            1          0\n",
      "11      1         0      1            0          0\n",
      "12      1         0      1            1          0\n",
      "13      1         1      0            0          1\n",
      "14      1         1      0            1          1\n",
      "15      1         1      1            0          1\n",
      "16      1         1      1            1          1\n"
     ]
    }
   ],
   "source": [
    "# Number of observations/rows in data\n",
    "n = 1000\n",
    "\n",
    "# Simulate data, last column must be the target variable\n",
    "exercises = sample(c(0,1), replace = TRUE, size = n)\n",
    "drinks = sample(c(0,1), replace = TRUE, size = n)\n",
    "smokes = sample(c(0,1), replace = TRUE, size = n)\n",
    "relationship = sample(c(0,1), replace = TRUE, size = n)\n",
    "heart_pain = sample(c(0,1), replace = TRUE, size = n)\n",
    "\n",
    "# Create training data\n",
    "training_data = as.data.frame(cbind(drinks, exercises, smokes, relationship, heart_pain))\n",
    "\n",
    "# Test tree function\n",
    "tree_output = tree(training_data)\n",
    "\n",
    "# Print the output from the tree\n",
    "print(tree_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a> <br>\n",
    "## Predicting New Observations\n",
    "Now that the tree has been built, there must be a way to classify new observations. The function below will be used to predict the output for the created testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_tree = function(testing_data){\n",
    "  \n",
    "  # Empty matrix for storing predictions\n",
    "  predictions = matrix(0, nrow = dim(testing_data)[1])\n",
    "  \n",
    "  # Number of inputs\n",
    "  p = dim(testing_data)[2]\n",
    "  \n",
    "  # Make predictions for each row of testing data\n",
    "  for (i in c(1:(dim(testing_data)[1]))){\n",
    "    \n",
    "    # Check each row in the tree\n",
    "    for (j in c(1:dim(tree_output)[1])){\n",
    "  \n",
    "      # Exit loop if the inputs in the tree line-up with the testing data\n",
    "      if (sum(tree_output[j,][,1:p] == testing_data[i,]) == p){\n",
    "        break\n",
    "      }\n",
    "      \n",
    "    }\n",
    "    \n",
    "    # Store prediction in the kth element of predictions matrix\n",
    "    predictions[i] = as.numeric(tree_output[j, p+1])\n",
    "    \n",
    "  }\n",
    "  \n",
    "  # Return the predictions\n",
    "  return(predictions)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a> <br>\n",
    "### Simulate Testing Data\n",
    "Testing data will be created below to predict new observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      [,1]\n",
      " [1,]    1\n",
      " [2,]    1\n",
      " [3,]    1\n",
      " [4,]    0\n",
      " [5,]    1\n",
      " [6,]    0\n",
      " [7,]    1\n",
      " [8,]    1\n",
      " [9,]    0\n",
      "[10,]    0\n"
     ]
    }
   ],
   "source": [
    "# Number of observations/rows in data\n",
    "n = 10\n",
    "\n",
    "# Inputs\n",
    "exercises = sample(c(0,1), replace = TRUE, size = n)\n",
    "drinks = sample(c(0,1), replace = TRUE, size = n)\n",
    "smokes = sample(c(0,1), replace = TRUE, size = n)\n",
    "relationship = sample(c(0,1), replace = TRUE, size = n)\n",
    "\n",
    "# Create data frame\n",
    "testing_data = as.data.frame(cbind(drinks, exercises, smokes, relationship))\n",
    "\n",
    "# Test predictions\n",
    "predictions = predict_tree(testing_data)\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"10\"></a> <br>\n",
    "## References\n",
    "1. https://blog.quantinsti.com/gini-index/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
